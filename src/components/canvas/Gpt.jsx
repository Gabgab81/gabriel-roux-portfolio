/*
Auto-generated by: https://github.com/pmndrs/gltfjsx
Command: npx gltfjsx@6.1.12 public/models/gpt.glb
*/
import * as THREE from "three";
import React, { useEffect, useRef, useState } from 'react';
import { useGLTF, useAnimations, useFBX, useCursor } from '@react-three/drei';
import { FlakesTexture } from 'three-stdlib';

export function Gpt(props) {
  const group = useRef()

  //Cursor
  // const [hovered, setHovered] = useState()
  // useCursor(hovered,/*'pointer', 'auto'*/)
  //Cursor

  //Model
  const [texture] = useState(() => new THREE.CanvasTexture(new FlakesTexture(), THREE.UVMapping, THREE.RepeatWrapping, THREE.RepeatWrapping))
  const { nodes, materials } = useGLTF('/public/models/gpt.glb')
  // console.log(nodes)
  //Moldel

  //Animations
  const { animations: typingAnimation } = useFBX("public/animations/Typing.fbx")
  const { animations: sittingAnimation } = useFBX("public/animations/Sitting.fbx")
  typingAnimation[0].name = "typing";
  sittingAnimation[0].name = "sitting";
  //Animations

 

  //Mixer for the addEvenListener
  // const model = useGLTF('/public/models/gpt.glb')
  // console.log(model)
  // let mixer = new THREE.AnimationMixer(model.scene)

  // const sittingClip = THREE.AnimationClip.findByName(sittingAnimation, "sitting");
  // const sittingAction = mixer.clipAction(sittingClip);
  // sittingAction.play()

  //Mixer for the addEvenListener
  
  const { actions, mixer, clips } = useAnimations([typingAnimation[0], sittingAnimation[0]], group)
  
  const sittingClip = THREE.AnimationClip.findByName(clips, "sitting")
  // const sittingAction = mixer.clipAction(sittingClip)

  // console.log(clips)
  // console.log(sittingClip)

  // console.log(actions.sitting)
  // console.log(actions.sitting["_mixer"])
  // console.log(sittingAction)
  // let value = mixer.hasEventListener('finished', console.log("toto"));
  // console.log(value)
  // mixer.addEventListener('finished', console.log("finished"))
  useEffect(() => {
    
    actions["sitting"].setLoop(THREE.LoopOnce)
    actions["sitting"].clampWhenFinished = true
    actions.sitting.reset
    actions.sitting.play()
   
    mixer.addEventListener('finished', function(e) {
      actions.sitting.stop()
      
      actions.typing.reset()
      actions.typing.play()
    })
    // actions.typing.play()
  })

  return (
    <group ref={group} {...props} dispose={null}>
      <group name="Scene">
        <group name="Armature" scale={0.01}>
          <primitive object={nodes.mixamorigHips}/>
            <skinnedMesh onClick={() => console.log("gpt")} castShadow receiveShadow name="Alpha_Joints" geometry={nodes.Alpha_Joints.geometry} material={materials.Alpha_Joints_MAT} skeleton={nodes.Alpha_Joints.skeleton}>
            <meshStandardMaterial 
              metalness={1} 
              roughness={0.1} 
              color={materials.Alpha_Joints_MAT}  
              // color={"white"} 
            />
          </skinnedMesh>

          <skinnedMesh castShadow receiveShadow name="Alpha_Surface" geometry={nodes.Alpha_Surface.geometry} material={materials.Alpha_Body_MAT} skeleton={nodes.Alpha_Surface.skeleton} 
            onClick={() => {console.log("salut")}}
            onPointerOver={() => setHovered(true)} 
            onPointerOut={() => setHovered(false)}
          >
            <meshStandardMaterial
              metalness={0.4}
              roughness={0.2}
              // color={materials['Alpha_Body_MAT.001'].color}
              color={"white"}
              normalMap={texture}
              normalMap-repeat={[35, 35]}
              normalScale={[0.15, 0.15]}
            />
          </skinnedMesh>
          
        </group>
      </group>
    </group>
  )
}

useGLTF.preload('/public/models/gpt.glb')
